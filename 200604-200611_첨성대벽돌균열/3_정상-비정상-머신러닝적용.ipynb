{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 불러오기\n",
    "\n",
    "'1_훼손 영역에 대한 검출 가능성.ipynb'에서 생성한 데이터를 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "DATA_PATH = \"res/data/\"\n",
    "DATA_LIST_PATH = f\"{DATA_PATH}.datalist\"\n",
    "\n",
    "# --------------------------------\n",
    "\n",
    "# 1. 불러와야 할 데이터들의 파일명 수집\n",
    "if not os.path.exists(DATA_PATH): raise Exception(\"No data.\")\n",
    "\n",
    "file_basename_list = []\n",
    "\n",
    "with open(DATA_LIST_PATH, \"r\") as f:\n",
    "    file_basename_list = f.readlines()\n",
    "    file_basename_list = [file_basename.rstrip() for file_basename in file_basename_list]\n",
    "\n",
    "# --------------------------------\n",
    "\n",
    "# 2. 데이터를 불러오는 함수\n",
    "def load(file_basename_list=file_basename_list):\n",
    "    for file_basename in file_basename_list:\n",
    "        file_name, file_extension = os.path.splitext(file_basename)\n",
    "\n",
    "        raw          = cv2.imread(f\"{DATA_PATH}{file_basename}\",                          cv2.IMREAD_COLOR)\n",
    "        mask         = cv2.imread(f\"{DATA_PATH}{file_name}_mask{file_extension}\",         cv2.IMREAD_GRAYSCALE)\n",
    "        mask_colored = cv2.imread(f\"{DATA_PATH}{file_name}_mask-colored{file_extension}\", cv2.IMREAD_COLOR)\n",
    "\n",
    "        if raw is None:\n",
    "            raise Exception(f\"Imread failed: {file_basename} from {file_basename_list}\")\n",
    "\n",
    "        yield file_basename, raw, mask, mask_colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_list = list(load())\n",
    "\n",
    "import math\n",
    "\n",
    "class CV2_Interface_HEPHEIR:\n",
    "    def __init__(self, win_name, data_list=data_list):\n",
    "        self.mx = 0\n",
    "        self.my = 0\n",
    "\n",
    "        self.win_name = win_name\n",
    "        self.trackbar_name = 'Choose Image'\n",
    "\n",
    "        self.file_basename = ''\n",
    "        self.frame_raw = None\n",
    "        self.frame_mask = None\n",
    "        self.frame_mask_colored = None\n",
    "\n",
    "        self.data_list = data_list\n",
    "\n",
    "        cv2.namedWindow(self.win_name)\n",
    "        cv2.setMouseCallback(self.win_name, self.onMouse)\n",
    "        cv2.createTrackbar(self.trackbar_name, self.win_name, 0, len(self.data_list)-1, self.onTrackbarChange)\n",
    "\n",
    "        self.updateDataset(self.data_list[0])\n",
    "\n",
    "    # with 문 지원.\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, type, value, traceback):\n",
    "        cv2.destroyWindow(self.win_name)\n",
    "\n",
    "    # --------------------------------\n",
    "\n",
    "    def onMouse(self, event,x,y,flags,param):\n",
    "        \"\"\"마우스 포인터의 좌표 갱신\"\"\"\n",
    "        if event == cv2.EVENT_MOUSEMOVE:\n",
    "            self.mx = x\n",
    "            self.my = y\n",
    "\n",
    "    def onTrackbarChange(self, x):\n",
    "        self.updateDataset(self.data_list[x])\n",
    "    \n",
    "    def updateDataset(self, data):\n",
    "        file_basename, frame_raw, frame_mask, frame_mask_colored = data\n",
    "\n",
    "        self.file_basename = file_basename\n",
    "        self.frame_raw = frame_raw\n",
    "        self.frame_mask = frame_mask\n",
    "        self.frame_mask_colored = frame_mask_colored\n",
    "\n",
    "    # --------------------------------\n",
    "\n",
    "    def makePoints(self, n, cx, cy, min_point, max_point):\n",
    "        \"\"\"중심의 좌표(cx,cy)와 한 변의 길이(n)을 이용하여 정사각형의 두 꼭짓점의 좌표를 계산.\"\"\"\n",
    "        x0, y0 = math.floor(cx - n/2), math.floor(cy - n/2)\n",
    "        x1, y1 = math.floor(cx + n/2), math.floor(cy + n/2)\n",
    "\n",
    "        # 범위 밖 좌표를 방지하기 위한 보정\n",
    "        dx, dy = 0, 0\n",
    "        padding = 4\n",
    "\n",
    "        minx, miny = min_point\n",
    "        maxx, maxy = max_point\n",
    "        \n",
    "        if (x0 < minx): dx = minx -x0 + padding\n",
    "        if (x1 > maxx): dx = maxx -x1 - padding\n",
    "\n",
    "        if (y0 < miny): dy = miny -y0 + padding\n",
    "        if (y1 > maxy): dy = maxy -y1 - padding\n",
    "\n",
    "        if dx * dy == 0:\n",
    "            return x0, y0, x1, y1\n",
    "        else:\n",
    "            return self.makePoints(n, cx+dx, cy+dy, min_point, max_point)\n",
    "\n",
    "    # --------------------------------\n",
    "\n",
    "    def updateFrame(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 선호/비선호 - 정상/비정상 영역 판단\n",
    "\n",
    "다음과 같이 레이블을 부여한다.\n",
    "\n",
    "* 비선호(정상): 0\n",
    "* 선호(훼손): 1\n",
    "\n",
    "### 2.1 아래의 프로그램을 통해 데이터를 수집한다.\n",
    "\n",
    "* OpenCV에서 제공하는 기능을 이용:\n",
    "    * 화면위에 마우스 커서를 올리면, 28x28크기의 정사각형 테두리가 나타난다.\n",
    "    * 숫자키 0~9를 입력하면, 입력한 숫자가 클래스의 이름(레이블)이 되어 저장된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 위에서 생성한 클래스의 서브클래스를 두 개 생성하여, 다음과 같은 용도로 사용한다.  \n",
    "* 학습 데이터 생성 모델\n",
    "* 데이터 예측 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 코드에 이어서...\n",
    "\n",
    "from src.dataset import save\n",
    "\n",
    "class DATASET_CREATE(CV2_Interface_HEPHEIR):\n",
    "    def __init__(self):\n",
    "        super().__init__('create dataset')\n",
    "\n",
    "    # @Override\n",
    "    def updateFrame(self, key):\n",
    "        h, w = self.frame_raw.shape[:2]\n",
    "\n",
    "        frame_addWeighted = cv2.addWeighted(self.frame_raw, 0.75, self.frame_mask_colored, 0.75, 0)\n",
    "        x0, y0, x1, y1 = self.makePoints(28, self.mx, self.my, (0, 0), (w, h))\n",
    "\n",
    "        cv2.rectangle(frame_addWeighted, (x0,y0), (x1,y1), (0,0,255), 1)\n",
    "        cv2.imshow(self.win_name, frame_addWeighted)\n",
    "\n",
    "        if key in \"0123456789\":\n",
    "            x, y = self.frame_raw[y0:y1, x0:x1], key\n",
    "            save([x], [y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 코드에 이어서...\n",
    "\n",
    "with DATASET_CREATE() as datasetCreate:\n",
    "    while True:\n",
    "        key = chr(cv2.waitKey(10) & 0xFF)\n",
    "\n",
    "        if key == 'q': break\n",
    "        else: datasetCreate.updateFrame(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 앞서 구현한 모델들을 실행하여 결과를 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# 위 코드에 이어서...\n",
    "\n",
    "buildModel = False\n",
    "\n",
    "if buildModel:\n",
    "    import tensorflow as tf\n",
    "    model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=32,\n",
    "                kernel_size=(3,3),\n",
    "                padding='same',\n",
    "                activation='relu',\n",
    "                input_shape=(28,28,3)),\n",
    "            tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "            tf.keras.layers.Dropout(0.25),\n",
    "            \n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=32,\n",
    "                kernel_size=(3,3),\n",
    "                padding='same',\n",
    "                activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "            tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "            tf.keras.layers.Flatten(),\n",
    "\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "            tf.keras.layers.Dense(28, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "            tf.keras.layers.Dense(2, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "    # --------------------------------\n",
    "\n",
    "    from src.dataset import load\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = load('res/data/classes')\n",
    "\n",
    "    x_train, y_train = x_train / 255.0, y_train / 255.0\n",
    "    x_test,  y_test  = x_test  / 255.0, y_test  / 255.0\n",
    "    model.fit(x_train, y_train, epochs=16)\n",
    "    model.evaluate(x_test, y_test)\n",
    "\n",
    "    model.save('model/model_3_epoch=16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 코드에 이어서...\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class DATASET_PREDICT(CV2_Interface_HEPHEIR):\n",
    "    def __init__(self):\n",
    "        super().__init__('predict data')\n",
    "        self.model = tf.keras.models.load_model('model/model_3_epoch=16')\n",
    "    \n",
    "    # @Override\n",
    "    def updateFrame(self):\n",
    "        h, w = self.frame_raw.shape[:2]\n",
    "        x0, y0, x1, y1 = self.makePoints(28, self.mx, self.my, (0, 0), (w, h))\n",
    "\n",
    "        frame_cut = self.frame_raw[y0:y1, x0:x1]\n",
    "        \n",
    "        predict = self.model.predict(np.expand_dims(frame_cut, axis=0))[0]\n",
    "        predict = np.where(predict == max(predict))[0][0]\n",
    "\n",
    "        frame_out = cv2.addWeighted(self.frame_raw, 0.75, self.frame_mask_colored, 0.75, 0)\n",
    "\n",
    "        cv2.putText(frame_out, f\"{predict}\", (16,16), cv2.FONT_HERSHEY_PLAIN, 1.2, (0,0,255), lineType=cv2.LINE_AA)\n",
    "        cv2.rectangle(frame_out, (x0,y0), (x1,y1), (0,0,255), 1)\n",
    "\n",
    "        cv2.imshow(self.win_name, frame_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_4_input to have shape (28, 28, 3) but got array with shape (28, 27, 3)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4fa45473f26d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdatasetPredict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdateFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-8c0d05ca44cf>\u001b[0m in \u001b[0;36mupdateFrame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mframe_cut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_cut\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    427\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[0;32m--> 646\u001b[0;31m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[1;32m    647\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2383\u001b[0;31m         batch_size=batch_size)\n\u001b[0m\u001b[1;32m   2384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[0;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[1;32m   2408\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2409\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2410\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2412\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    580\u001b[0m                              \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m                              str(data_shape))\n\u001b[0m\u001b[1;32m    583\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_4_input to have shape (28, 28, 3) but got array with shape (28, 27, 3)"
     ]
    }
   ],
   "source": [
    "# 위 코드에 이어서...\n",
    "\n",
    "with DATASET_PREDICT() as datasetPredict:\n",
    "\n",
    "    while True:\n",
    "        key = cv2.waitKey(10)\n",
    "\n",
    "        if key == ord('q'): break\n",
    "        else: datasetPredict.updateFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitmlconda56395923f6734d2e9d871b41acf277cc",
   "display_name": "Python 3.7.7 64-bit ('ml': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}