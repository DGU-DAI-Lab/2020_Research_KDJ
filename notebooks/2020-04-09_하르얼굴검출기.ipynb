{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 서론\n",
    "\n",
    "## 주제\n",
    "\n",
    "### Face Detection\n",
    "with OpenCV :: Cascade Classifier\n",
    "\n",
    "\n",
    "## 목표\n",
    "* 동영상으로부터 객체 판별 -> Camera\n",
    "* 영상처리를 이용 -> OpenCV\n",
    "\n",
    "## 개념\n",
    "\n",
    "### Haar Classifier\n",
    "\n",
    "---\n",
    "\n",
    "# 본론\n",
    "\n",
    "## 설계\n",
    "### 1. 데이터 셋 확보\n",
    "\n",
    "Haar cascade 분류기의 경우, OpenCV에 몇 모델들이 내장되어있음.\n",
    "본 실험에서는 OpenCV의 공개 프로젝트 Github 레포지토리에서 모델을 불러온다.\n",
    "모델들은 xml 파일의 형태로 존재하며 다음의 페이지에서 확인할 수 있다.\n",
    "* https://github.com/opencv/opencv/tree/master/data/haarcascades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "def download(base_url, files, path_downloads):\n",
    "    for f in files:\n",
    "        urllib.request.urlretrieve(base_url+f,path_downloads+f)\n",
    "\n",
    "# ---\n",
    "\n",
    "PATH_DOWNLOADS = './resources/'\n",
    "BASE_URL = 'https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/'\n",
    "FILES = ['haarcascade_frontalface_default.xml',\n",
    "         'haarcascade_eye.xml']\n",
    "\n",
    "download(BASE_URL, FILES, PATH_DOWNLOADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 얼굴 및 눈 검출기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "PATH = './resources/'\n",
    "PRE_TRAINED_MODELS = {'frontalface': 'haarcascade_frontalface_default.xml',\n",
    "                      'eye': 'haarcascade_eye.xml'}\n",
    "\n",
    "FACE_THICKNESS, FACE_COLOR = 2, (255,0,0)\n",
    "EYES_THICKNESS, EYES_COLOR = 1, (0,255,0)\n",
    "\n",
    "\n",
    "classifier = {'face': cv2.CascadeClassifier(PATH + PRE_TRAINED_MODELS['frontalface']),\n",
    "              'eye': cv2.CascadeClassifier(PATH + PRE_TRAINED_MODELS['eye'])}\n",
    "\n",
    "# Camera Settings\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Mainloop\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = classifier['face'].detectMultiScale(gray, 1.3, 3)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), FACE_COLOR, FACE_THICKNESS)\n",
    "        roi_gray, roi_color = gray[y:y+h, x:x+w], frame[y:y+h, x:x+w]\n",
    "\n",
    "        eyes = classifier['eye'].detectMultiScale(roi_gray)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color, (ex,ey), (ex+ew, ey+eh), EYES_COLOR, EYES_THICKNESS)\n",
    "                \n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    key = cv2.waitKey(8)\n",
    "    if key == 27: break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 결론\n",
    "\n",
    "## 해석\n",
    "## 고찰\n",
    "## 계획\n",
    "\n",
    "* Haar외에 다양한 영상의 Feature을 추출하는 방법에 대한 조사 및 비교 (SIFT, HOD, Haar, Ferns, LBP, MCT 등...)\n",
    "\n",
    "---\n",
    "\n",
    "# 부록\n",
    "\n",
    "### 1. 얼굴 및 눈 검출기 & Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "PATH = './resources/'\n",
    "PRE_TRAINED_MODELS = {'frontalface': 'haarcascade_frontalface_default.xml',\n",
    "                      'eye': 'haarcascade_eye.xml'}\n",
    "\n",
    "FACE_THICKNESS, FACE_COLOR = 2, (255,0,0)\n",
    "EYES_THICKNESS, EYES_COLOR = 1, (0,255,0)\n",
    "\n",
    "\n",
    "classifier = {'face': cv2.CascadeClassifier(PATH + PRE_TRAINED_MODELS['frontalface']),\n",
    "              'eye': cv2.CascadeClassifier(PATH + PRE_TRAINED_MODELS['eye'])}\n",
    "\n",
    "# Camera Settings\n",
    "cap = cv2.VideoCapture(0)\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "out = cv2.VideoWriter('face_detect.avi',\n",
    "                      cv2.VideoWriter_fourcc('M','J','P','G'),\n",
    "                      10,\n",
    "                      (frame_width,frame_height))\n",
    "\n",
    "# Mainloop\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = classifier['face'].detectMultiScale(gray, 1.3, 3)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), FACE_COLOR, FACE_THICKNESS)\n",
    "        roi_gray, roi_color = gray[y:y+h, x:x+w], frame[y:y+h, x:x+w]\n",
    "\n",
    "        eyes = classifier['eye'].detectMultiScale(roi_gray)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color, (ex,ey), (ex+ew, ey+eh), EYES_COLOR, EYES_THICKNESS)\n",
    "                \n",
    "    cv2.imshow('frame', frame)\n",
    "    out.write(frame)\n",
    "\n",
    "    key = cv2.waitKey(8)\n",
    "    if key == 27: break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('ml': conda)",
   "language": "python",
   "name": "python37764bitmlconda56395923f6734d2e9d871b41acf277cc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
